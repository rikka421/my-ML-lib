{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:11.910828Z",
     "start_time": "2024-10-28T13:14:11.897825Z"
    }
   },
   "source": "print(\"hello world\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:15.498287Z",
     "start_time": "2024-10-28T13:14:13.816134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__) "
   ],
   "id": "acd5abf8e73f0f68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0+cu124\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:16.105445Z",
     "start_time": "2024-10-28T13:14:16.088416Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "bc9dbf907cbc3bfb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:17.072267Z",
     "start_time": "2024-10-28T13:14:17.051267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inner_size = 128\n",
    "\n",
    "image = np.random.rand(64, 28*28)\n",
    "weight = np.random.rand(28*28, inner_size)\n",
    "bias = np.random.rand(inner_size)\n",
    "print(image.shape, weight.shape, bias.shape)\n",
    "\n",
    "result = image @ weight + bias\n",
    "print(result.shape)"
   ],
   "id": "326b75bfb4dd1ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 784) (784, 128) (128,)\n",
      "(64, 128)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:21.751223Z",
     "start_time": "2024-10-28T13:14:20.162209Z"
    }
   },
   "cell_type": "code",
   "source": "from torchvision import datasets, transforms",
   "id": "6c36f4ca4db3e5de",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:22.761394Z",
     "start_time": "2024-10-28T13:14:22.755395Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import DataLoader",
   "id": "90c4804c9f66aefc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:14:46.177127Z",
     "start_time": "2024-10-28T13:14:24.263311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    # transforms.Normalize((0.5,), (0.5,))  # 归一化\n",
    "    transforms.Lambda(lambda x: x.view(-1)),  # 张量转换为一维\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)),  # onehot\n",
    "])\n",
    "\n",
    "# 加载训练和测试数据集\n",
    "# m * (torch.Size([1, 28, 28]), int), 每个样本为(X, y)元组, 其中X是图片, y是标签\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    "    )\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ],
   "id": "8f4a73886fb3ecf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:15:15.291785Z",
     "start_time": "2024-10-28T13:15:05.524915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for images, labels in train_loader:\n",
    "    pass\n",
    "    # print(images.shape)\n",
    "    # print(labels.shape)"
   ],
   "id": "d1de6bc309182c87",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:15:17.761228Z",
     "start_time": "2024-10-28T13:15:17.745220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义一个简单的神经网络\n",
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 定义层：一个两层的全连接网络\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, inner_size)  # 输入层到隐藏层\n",
    "        self.fc2 = torch.nn.Linear(inner_size, 10)  # 隐藏层到输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # 展平输入（假设输入是28x28图像）\n",
    "        x = torch.relu(self.fc1(x))  # 激活函数 ReLU\n",
    "        x = self.fc2(x)  # 输出层\n",
    "        return x\n"
   ],
   "id": "4482320c3deda9b8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:45:16.056599Z",
     "start_time": "2024-10-28T13:45:16.036622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def d_CrossEntropyLoss(outputs, labels):\n",
    "    # outputs: m * 10, labels: m * 10 -> m * 10\n",
    "    # result = d   [- sum (y_i + log sum e^y ) / N] / dy_i = \n",
    "    outputs = outputs.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    exp_tar = np.exp(outputs)\n",
    "    exp_sum = np.sum(np.exp(outputs), axis=1).reshape(len(labels), 1)\n",
    "    # result = - torch.log(exp_tar / exp_sum) / len(labels)\n",
    "    \n",
    "    pre_d_value = exp_tar / exp_sum\n",
    "    \n",
    "    pre_d_value -= outputs * labels\n",
    "    \n",
    "    pre_d_value *= 1 / len(labels)\n",
    "    return pre_d_value\n",
    "    "
   ],
   "id": "111995470bf5f338",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:36:40.666935Z",
     "start_time": "2024-10-28T13:36:40.644905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "# 训练函数\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=5, my_model=True):\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            # 前向传播\n",
    "            if my_model:\n",
    "                images = images.numpy()\n",
    "                outputs = model.forward(images)\n",
    "                outputs = torch.from_numpy(outputs)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            if my_model:\n",
    "                # Loss = -1/N (y - log sum e^hat_y)\n",
    "                # d log sum e^hat_y / d hat_y = e^hat_y / log sum e^hat_y\n",
    "                pre_d_value = d_CrossEntropyLoss(outputs, labels)\n",
    "                model.backward(pre_d_value, lr=1e-3)\n",
    "            else:\n",
    "                # 反向传播和优化\n",
    "                optimizer.zero_grad()  # 清除上一步的梯度\n",
    "                loss.backward()  # 计算梯度\n",
    "                optimizer.step()  # 更新参数\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "7621bbddeb0f89d2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:15:21.384033Z",
     "start_time": "2024-10-28T13:15:21.377523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, test_loader, my_model=True):\n",
    "    if not my_model:\n",
    "        model.eval()  # 切换到评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            if my_model:\n",
    "                images = images.numpy()\n",
    "                outputs = model.forward(images)\n",
    "                outputs = torch.from_numpy(outputs)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test dataset: {100 * correct / total:.2f}%')\n"
   ],
   "id": "1f2257aeabf82c2d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:38:22.349396Z",
     "start_time": "2024-10-28T13:38:22.335005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeuralNetworks import NeuralNetwork\n",
    "from NeuralNetworks import Layer\n",
    "\n",
    "# 定义自己的神经网络\n",
    "class MyNN(NeuralNetwork):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # 定义层：一个两层的全连接网络\n",
    "        self.fc1 = Layer(input_size, inner_size)  # 输入层到隐藏层\n",
    "        self.fc2 = Layer(inner_size, output_size, activation_function=lambda x:x)  # 隐藏层到输出层\n",
    "        super(MyNN, self).__init__(input_size, output_size, [self.fc1, self.fc2])\n"
   ],
   "id": "5ecad5b0ee0984c9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:46:38.148017Z",
     "start_time": "2024-10-28T13:45:19.853968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建网络实例\n",
    "model = MyNN(28*28, 10)\n",
    "optimizer = None  # 损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 交叉熵损失（用于分类任务）\n",
    "\n",
    "# 开始训练\n",
    "train(model, train_loader, criterion, optimizer, my_model=True)"
   ],
   "id": "a92a287823e65180",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.3026\n",
      "Epoch [2/5], Loss: 2.3025\n",
      "Epoch [3/5], Loss: 2.3026\n",
      "Epoch [4/5], Loss: 2.3025\n",
      "Epoch [5/5], Loss: 2.2993\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:47:05.352032Z",
     "start_time": "2024-10-28T13:47:03.238641Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate(model, test_loader, my_model=True)",
   "id": "e0bc7f7cd9d064a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test dataset: 10.67%\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:19:50.500934Z",
     "start_time": "2024-10-28T13:15:26.221525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建网络实例\n",
    "model = SimpleNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用 Adam 优化器# 损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 交叉熵损失（用于分类任务）\n",
    "\n",
    "# 开始训练\n",
    "train(model, train_loader, criterion, optimizer, my_model=False)"
   ],
   "id": "6e0eea5a3292bfc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0349\n",
      "Epoch [2/5], Loss: 0.3161\n",
      "Epoch [3/5], Loss: 0.1635\n",
      "Epoch [4/5], Loss: 0.0341\n",
      "Epoch [5/5], Loss: 0.0544\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 评估模型\n",
    "evaluate(model, test_loader, my_model=False)"
   ],
   "id": "ace3b4394900950f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allone",
   "language": "python",
   "name": "allone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
